#!/usr/bin/env python

###
### TieDIE: Tied Diffusion for Network Discovery
###
###	Version: 
###
###		Multiple (>= 3 inputs) Development Version
###
###	Authors: 
###
###		Evan Paull (epaull@soe.ucsc.edu)
###
###	Requirements:
###
### 	python 2.7.X
###		numpy 1.7+ (with pre-computed kernels)
###		scipy 0.12+ (for on-the-fly kernel generation)
###
### Minimum Inputs: 
###		
###		- separate source/target input heat files: tab-separated, 3 columns each with <gene> <input heat> <sign (+/-)>
###		- a search pathway in .sif format (geneA <interaction> geneB)
###
### Outputs:
###
###		Creates a directory in the current working directory, and writes all output to that
###		Information and warnings are logged to standard error


import os, sys
from collections import defaultdict
from optparse import OptionParser
parser = OptionParser()
parser.add_option("-k","--kernel",dest="kernel",action="store",type="string",default=None,help="\
Pre-computed heat diffusion kernel in tab-delimited form. Should have both a header and row labels. \
The program will attempt to use scipy to generate a kernel if none is supplied.")
parser.add_option("-n","--network",dest="network",action="store",default=None,help="\
.sif network file for the curated pathway to search. <source>   <(-a>,-a|,-t>,-t|,-component>)> <target>")
parser.add_option("-s","--size",dest="size",action="store",default=1,type="float",help="\
Network size control factor (default 1)")
# data specific for patient-specific networks here
parser.add_option("--p_expr",dest="p_expr",action="store",default=None,type="string",help="\
Normal-subtracted Gene Expression Matrix, rows = Genes, columns = Samples")
parser.add_option("--p_mut",dest="p_mut",action="store",default=None,type="string",help="\
Matrix of Mutation Calls, per Patient")
parser.add_option("-m","--min_hub",dest="min_hub",action="store",default=10,type="int",help=\
"minimum number of genes in regulon to consider a TF")
# optional: ranked list of heats from a TieDIE concensus network: compute GSEA enrichment for these
parser.add_option("--node_ranks",dest="node_ranks",action="store",default=None,type="string",help=\
"minimum number of genes in regulon to consider a TF")

# optional inputs here:
(opts, args) = parser.parse_args()

# local imports assume the directory structure from github . 
sys.path.append(os.path.dirname(sys.argv[0])+'/../lib')
from kernel import Kernel
import tiedie_util
from tiedie_util import *
from master_reg import ActivityScores, SSActivityScores

if opts.kernel is None:
	sys.stderr.write("Warning: No kernel file supplied, will use SCIPY to compute the matrix exponential, t=0.1...\n")
	from kernel_scipy import SciPYKernel

def min(vals):
	min = vals[0]
	for v in vals:
		if v < min:
			min = v

	return min

# NOTE should all these functions be moved to a file in lib, as they currently
# appear in multiple files in bin? --ESR
def getProduct(diffused):
	gene_scores = {}
	for file in diffused:
		# a hash of hashes: file is the index
		for (gene, heat) in diffused[file].iteritems():
			if gene not in gene_scores:
				gene_scores[gene] = []
			gene_scores[gene].append(heat)

	gene_products = {}
	for gene in gene_scores:
		product = 1
		for v in gene_scores[gene]:
			product *= v
		gene_products[gene] = product
	
	return gene_products
 
def getMinHeats(consider_top, diffused):
	"""
	Gets the minimum heats for all genes, from a number of diffused heat vectors.

	Input:
        consider_top -- ???
		diffused = { 'set':{'gene1':heat1, 'gene2':...} -- what?

	Returns:
		A minimum-heat vector over all genes represented as a dict where the
        name of the gene is the key
			
	"""

	gene_scores = {}
	for file in diffused:
		# a hash of hashes: file is the index
		for (gene, heat) in diffused[file].iteritems():
			if gene not in gene_scores:
				gene_scores[gene] = []
			gene_scores[gene].append(heat)

  
	min_gene_values = {} 
	for gene in gene_scores:
		values = gene_scores[gene]
		# get the top X
		min_gene_values[gene] = min(sorted(values, reverse=True)[0:consider_top])

	return min_gene_values

def extractSubnetwork(input_heats, diffused_heats, size_control):
	"""
	Generate a spanning subnetwork from the supplied inputs, diffused heats and 
	size control cutoff

	Input:
		- input heats (in what format?)
		- diffused input heats (in what format?)
		- size control factor (explain what this means?)

	Returns: tuple containing the following elements
		- spanning network in 'network[node] = [(edge_type, other_node)]' format
		- set of node ID strings in that network
        - linker heats
        - linker cutoff
	"""

	linker_cutoff = None
	linker_nodes = None
	linker_scores = None

	# get linker heats as a function of input sets
	linker_heats = None
	linker_heats = getMinHeats(2, diffused_heats)

	EPSILON = 0.0001
	linker_cutoff = None
	score = None
	linkers = set()
	linker_scores = {}
	for (l,h) in sorted(linker_heats.iteritems(), key=operator.itemgetter(1), reverse=True):
        # NOTE why is this function returning the last value of linker_cutoff?
		linker_cutoff = h-EPSILON
		score, size_frac = scoreLinkersMulti(input_heats, linker_heats,
                linker_cutoff, size_control)
		linkers.add(l)
		linker_scores[l] = h
		if size_frac > 1:
			break

	# set of input heats
	ugraph = None
	# USE JUST LINKER GENES
	active_nodes = set(linkers)
	ugraph = connectedSubnets(network, active_nodes)
	if not ugraph or len(ugraph) == 0:
		return (None, None, None, None)
	subnet_soln = mapUGraphToNetwork(ugraph, network)
	
	subnet_soln_nodes = set() # set of node ID strings contained in the subnet
	for s in subnet_soln:
		subnet_soln_nodes.add(s)
		for (i,t) in subnet_soln[s]:
			subnet_soln_nodes.add(t)

	return (subnet_soln, subnet_soln_nodes, linker_heats, linker_cutoff)

def thresholdEvents(data, threshold):

	filtered = {}
	for event in data:
		if data[event] >= threshold:
			filtered[event] = data[event]

	return filtered

def normalizeHeats(data):
	"""

	"""
	normalized = {}
	signs = {}
	sum = 0.0
	for (event, val) in data.items():
		sum += abs(val)

	for (event, val) in data.items():
		sign = "+"
		if val < 0:
			sign = "-"
		normalized[event] = abs(val) / sum
		signs[event] = sign

	return (normalized, signs)
	
# parse network file: use for input validation if heat nodes are not in network
sys.stderr.write("Parsing Network File..\n")
network = parseNet(opts.network)
network_nodes = getNetworkNodes(network)

out_prefix = "."
output_folder = out_prefix+"/TieDIE.PSN"

if not os.path.exists(output_folder):
	os.mkdir(output_folder)

#
# Diffusion Step:
#	Load the heat diffusion kernel and perform a kernel-multiply, or alternatively use supplied
# 	page-rank diffused vectors
#

if opts.kernel is not None:
	sys.stderr.write("Loading Heat Diffusion Kernel..\n")
	# load a heat diffusion kernel to perform diffusion
	diffuser = Kernel(opts.kernel)
else:
	sys.stderr.write("Using SCIPY to compute the matrix exponential, t=0.1...\n")
	# No kernel supplied: use SCIPY to generate a kernel on the fly, and then use it
	# for subsequent diffusion operations
	diffuser = SciPYKernel(opts.network)

# by convention, the first input should be the mutation data
sample_mut = parseMatrix(opts.p_mut)

# infer activity scores from the TF edges
ssAct = SSActivityScores(network, opts.p_expr, opts.min_hub)
sample_activities = ssAct.getActivities()

# heat scores from the TieDIE Consensus network
tiedie_heat_scores = None
if opts.node_ranks:
	tiedie_heat_scores, signs = parseHeats(opts.node_ranks)

stats = open(output_folder+"/network.stats.txt", 'w')
# generate a TieDIE network for each sample 
for sample_id in sample_mut:

	mutation_events = thresholdEvents(sample_mut[sample_id], 1)
	mut_heats, mut_signs = normalizeHeats(mutation_events)
	# hardcoded for now: z = 1.5
	tf_events = thresholdEvents(sample_activities[sample_id], 0.5)
	
	tf_heats, tf_signs = normalizeHeats(tf_events)

	input_heats = {}
	diffused_heats = {}
	input_heats['up'] = mut_heats		
	input_heats['down'] = tf_heats		
	diffused_heats['up'] = diffuser.diffuse(mut_heats)
	diffused_heats['down'] = diffuser.diffuse(tf_heats)
	subnet_soln, subnet_soln_nodes, linker_heats, linker_cutoff = extractSubnetwork(input_heats, diffused_heats, 1.0)
	if subnet_soln is None:
		print "No network found for sample:"+sample_id
		continue	
	print "Writing network for sample "+sample_id
	writeNetwork(subnet_soln, output_folder+"/"+sample_id+".sif")

	ES_score, pval = ActivityScores.getEnrichmentScore(network, tiedie_heat_scores, subnet_soln_nodes)
	stats.write("\t".join([sample_id, str(ES_score), str(pval)])+"\n")

stats.close()
